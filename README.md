## Root directory
* The .py file contains the full code with comments explaining pretty much the entire process.
* I provided two test videos to run the code on, selecting the other is done by changing the 'videoName' variable in the code.
* face_landmarker_v2_with_blendshapes.task is needed to run the code. This is a Mediapipe file.
* mediapipe_face_landmark_fullsize.png is a vidual representation of all the facial landmarks Mediapipe produces.

## 'example outputs' directory
* The videos in this directory are recordings of what running the code on the test videos should look like.
* The files ending in plot.csv contain the eye/mouth openness ratios of that run.
* The files ending in timecodes.csv contain the start & end of each blink/yawn detected.
